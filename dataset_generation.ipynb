{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs.minimal_jsp_env.util.jsp_generation.random_generator import RandomJSPGenerator, RandomJSPGeneratorPool, RandomJSPGeneratorOperationDistirbution, RandomJSPGeneratorWithJobPool\n",
    "from envs.minimal_jsp_env.entities import Operation, JSPInstance\n",
    "import json\n",
    "\n",
    "from envs.minimal_jsp_env.util.jsp_conversion.readers import JSPReaderGoogleOR, JSPReaderJSON\n",
    "from envs.minimal_jsp_env.util.jsp_conversion.writers import JSPWriterJSON"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reader / Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_matrices(jsp_instance: JSPInstance, display: bool = True):\n",
    "    machine_types = []\n",
    "    durations = []\n",
    "    for job in jsp_instance.jobs:\n",
    "        machine_types.append([operation.machine_type for operation in job])\n",
    "        durations.append([operation.duration for operation in job])\n",
    "        if display:\n",
    "            print([f\"({operation.machine_type}, {operation.duration})\" for operation in job])\n",
    "    \n",
    "    return machine_types, durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Operation(job_id=0, op_id=0, machine_type=0, duration=2),\n",
       "  Operation(job_id=0, op_id=1, machine_type=2, duration=1),\n",
       "  Operation(job_id=0, op_id=2, machine_type=1, duration=1)],\n",
       " [Operation(job_id=1, op_id=0, machine_type=2, duration=3),\n",
       "  Operation(job_id=1, op_id=1, machine_type=1, duration=9),\n",
       "  Operation(job_id=1, op_id=2, machine_type=2, duration=3)],\n",
       " [Operation(job_id=2, op_id=0, machine_type=2, duration=9),\n",
       "  Operation(job_id=2, op_id=1, machine_type=1, duration=9),\n",
       "  Operation(job_id=2, op_id=2, machine_type=0, duration=9)]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_instance = RandomJSPGenerator(num_jobs=3, num_operations=3, max_op_duration=9).generate()\n",
    "test_instance.jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 2], [2, 1], [1, 1]], [[2, 3], [1, 9], [2, 3]], [[2, 9], [1, 9], [0, 9]]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_instance = []\n",
    "for job in test_instance.jobs:\n",
    "    job_ops = [[i.machine_type, i.duration] for i in job]\n",
    "    or_instance.append(job_ops)\n",
    "or_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSPWriterJSON().write_instance(test_instance, \"test.json\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Operation(job_id=0, op_id=0, machine_type=0, duration=2),\n",
       "  Operation(job_id=0, op_id=1, machine_type=2, duration=1),\n",
       "  Operation(job_id=0, op_id=2, machine_type=1, duration=1)],\n",
       " [Operation(job_id=1, op_id=0, machine_type=2, duration=3),\n",
       "  Operation(job_id=1, op_id=1, machine_type=1, duration=9),\n",
       "  Operation(job_id=1, op_id=2, machine_type=2, duration=3)],\n",
       " [Operation(job_id=2, op_id=0, machine_type=2, duration=9),\n",
       "  Operation(job_id=2, op_id=1, machine_type=1, duration=9),\n",
       "  Operation(job_id=2, op_id=2, machine_type=0, duration=9)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSPReaderJSON().read_instance('test.json').jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropies for datasets with pool_size = 36\n",
    "\n",
    "entropy0_2 = [0.5, 0.5]\n",
    "entropy0_3 = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
    "entropy0_4 = [0.08333333333333333, 0.16666666666666666, 0.25, 0.08333333333333333, 0.4166666666666667]\n",
    "entropy0_5 = [0.3333333333333333, 0.16666666666666666, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.16666666666666666]\n",
    "entropy0_6 = [0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.16666666666666666, 0.08333333333333333, 0.16666666666666666, 0.16666666666666666, 0.08333333333333333]\n",
    "entropy0_7 = [0.05555555555555555, 0.1111111111111111, 0.027777777777777776, 0.05555555555555555, 0.05555555555555555, 0.16666666666666666, 0.16666666666666666, 0.05555555555555555, 0.027777777777777776, 0.027777777777777776, 0.08333333333333333, 0.027777777777777776, 0.05555555555555555, 0.05555555555555555, 0.027777777777777776]\n",
    "entropy0_8 = [0.16666666666666666, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.05555555555555555, 0.027777777777777776, 0.05555555555555555, 0.027777777777777776, 0.027777777777777776, 0.05555555555555555, 0.05555555555555555, 0.027777777777777776, 0.027777777777777776, 0.05555555555555555, 0.027777777777777776, 0.08333333333333333, 0.05555555555555555, 0.08333333333333333, 0.027777777777777776]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_instances = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entropy_val in range(2, 9, 1):\n",
    "\n",
    "    dir_path = f\"data/entropy_datasets/entropy0_{entropy_val}/\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    for i in range(number_of_instances):\n",
    "        instance = RandomJSPGeneratorOperationDistirbution(num_jobs=6, num_operations=6, max_op_duration=9).generate(eval(f\"entropy0_{entropy_val}\"))\n",
    "        file_name = f\"entropy0_{entropy_val}_{i}\"\n",
    "        JSPWriterJSON().write_instance(instance, f\"{dir_path}/{file_name}\", file_name)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "or_instance = JSPReaderGoogleOR().read_instance('data/entropy_datasets/entropy0_2/entropy0_2_21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ops = [str(i) for i in sum(or_instance, [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(all_ops).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entropy_val in range(2, 9, 1):\n",
    "\n",
    "    dir_path = f\"data/entropy_datasets/entropy0_{entropy_val}/\"\n",
    "    \n",
    "    for i in range(number_of_instances):\n",
    "        file_name = f\"entropy0_{entropy_val}_{i}\"\n",
    "        or_instance = JSPReaderGoogleOR().read_instance(f\"{dir_path}/{file_name}\")\n",
    "        all_ops = [str(i) for i in sum(or_instance, [])]\n",
    "        instance_distinct_ops = len(Counter(all_ops).keys())\n",
    "        distr_len = len(eval(f\"entropy0_{entropy_val}\"))\n",
    "\n",
    "        if distr_len != instance_distinct_ops:\n",
    "            print(f\"{dir_path}/{file_name}\")\n",
    "            print(f\"{distr_len} != {instance_distinct_ops}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge cases tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_min_entropy():\n",
    "\n",
    "    entropy_distribution = [1]\n",
    "    instance = RandomJSPGeneratorOperationDistirbution(num_jobs=6, num_operations=6, max_op_duration=9).generate(entropy_distribution)\n",
    "\n",
    "    assert instance.relative_entropy == 0\n",
    "\n",
    "def test_max_entropy():\n",
    "\n",
    "    entropy_distribution = [1/36 for i in range(36)]\n",
    "    instance = RandomJSPGeneratorOperationDistirbution(num_jobs=6, num_operations=6, max_op_duration=9).generate(entropy_distribution)\n",
    "\n",
    "    assert instance.relative_entropy == 1\n",
    "\n",
    "def test_6x6_entropies():\n",
    "    entropy0_2 = [0.5, 0.5]\n",
    "    entropy0_3 = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
    "    entropy0_4 = [0.08333333333333333, 0.16666666666666666, 0.25, 0.08333333333333333, 0.4166666666666667]\n",
    "    entropy0_5 = [0.3333333333333333, 0.16666666666666666, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.16666666666666666]\n",
    "    entropy0_6 = [0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.16666666666666666, 0.08333333333333333, 0.16666666666666666, 0.16666666666666666, 0.08333333333333333]\n",
    "    entropy0_7 = [0.05555555555555555, 0.1111111111111111, 0.027777777777777776, 0.05555555555555555, 0.05555555555555555, 0.16666666666666666, 0.16666666666666666, 0.05555555555555555, 0.027777777777777776, 0.027777777777777776, 0.08333333333333333, 0.027777777777777776, 0.05555555555555555, 0.05555555555555555, 0.027777777777777776]\n",
    "    entropy0_8 = [0.16666666666666666, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.05555555555555555, 0.027777777777777776, 0.05555555555555555, 0.027777777777777776, 0.027777777777777776, 0.05555555555555555, 0.05555555555555555, 0.027777777777777776, 0.027777777777777776, 0.05555555555555555, 0.027777777777777776, 0.08333333333333333, 0.05555555555555555, 0.08333333333333333, 0.027777777777777776]\n",
    "\n",
    "    for entropy_val in range(2, 9, 1):\n",
    "        entropy_distribution = eval(f\"entropy0_{entropy_val}\")\n",
    "        instance = RandomJSPGeneratorOperationDistirbution(num_jobs=6, num_operations=6, max_op_duration=9).generate(entropy_distribution)\n",
    "        assert abs(instance.relative_entropy-0.1*entropy_val)<=0.05\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_min_entropy()\n",
    "test_max_entropy()\n",
    "test_6x6_entropies()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c17c7798a234b4ec4e31009dea6d0ff377deb5cfd05df96186109883c898b2c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
