{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs.minimal_jsp_env.util.jsp_generation.random_generator import RandomJSPGenerator, RandomJSPGeneratorPool, RandomJSPGeneratorOperationDistirbution, RandomJSPGeneratorWithJobPool\n",
    "from envs.minimal_jsp_env.entities import Operation, JSPInstance\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reader / Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_matrices(jsp_instance: JSPInstance, display: bool = True):\n",
    "    machine_types = []\n",
    "    durations = []\n",
    "    for job in jsp_instance.jobs:\n",
    "        machine_types.append([operation.machine_type for operation in job])\n",
    "        durations.append([operation.duration for operation in job])\n",
    "        if display:\n",
    "            print([f\"({operation.machine_type}, {operation.duration})\" for operation in job])\n",
    "    \n",
    "    return machine_types, durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Operation(job_id=0, op_id=0, machine_type=0, duration=5),\n",
       "  Operation(job_id=0, op_id=1, machine_type=2, duration=7),\n",
       "  Operation(job_id=0, op_id=2, machine_type=2, duration=5)],\n",
       " [Operation(job_id=1, op_id=0, machine_type=1, duration=4),\n",
       "  Operation(job_id=1, op_id=1, machine_type=2, duration=3),\n",
       "  Operation(job_id=1, op_id=2, machine_type=1, duration=6)],\n",
       " [Operation(job_id=2, op_id=0, machine_type=1, duration=5),\n",
       "  Operation(job_id=2, op_id=1, machine_type=1, duration=6),\n",
       "  Operation(job_id=2, op_id=2, machine_type=1, duration=3)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_instance = RandomJSPGenerator(num_jobs=3, num_operations=3, max_op_duration=9).generate()\n",
    "test_instance.jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSPWriterJSON:\n",
    "    def write_instance(self, instance: JSPInstance, path: str, id: str):\n",
    "        machine_types, durations = get_job_matrices(instance, display=False)\n",
    "        json_file = {\n",
    "            'machine_types': machine_types, \n",
    "            'durations': durations, \n",
    "            'num_ops_per_job' : instance.num_ops_per_job,\n",
    "            'max_op_time': instance.max_op_time,\n",
    "            'id': id,\n",
    "            'opt_time': instance.opt_time\n",
    "            }\n",
    "        with open(path, 'w') as file:\n",
    "            json.dump(json_file, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSPReaderJSON:\n",
    "    def read_instance(self, path: str) -> JSPInstance:       \n",
    "\n",
    "        with open(path, 'r') as file:\n",
    "            input_file = json.load(file)\n",
    "\n",
    "        jobs = []\n",
    "\n",
    "        for job_id, (job_machine_types, job_durations) in enumerate(zip(input_file['machine_types'], input_file['durations'])):\n",
    "            \n",
    "            operations = []\n",
    "            for operation_id, (operation_machine_type, operation_duration) in enumerate(zip(job_machine_types, job_durations)):\n",
    "                operations.append(Operation(job_id, operation_id, operation_machine_type, operation_duration))\n",
    "            \n",
    "            jobs.append(operations)\n",
    "\n",
    "\n",
    "        return JSPInstance(jobs, input_file['num_ops_per_job'], input_file['max_op_time'], input_file['id'], input_file['opt_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSPWriterJSON().write_instance(test_instance, \"test.json\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Operation(job_id=0, op_id=0, machine_type=0, duration=5),\n",
       "  Operation(job_id=0, op_id=1, machine_type=2, duration=7),\n",
       "  Operation(job_id=0, op_id=2, machine_type=2, duration=5)],\n",
       " [Operation(job_id=1, op_id=0, machine_type=1, duration=4),\n",
       "  Operation(job_id=1, op_id=1, machine_type=2, duration=3),\n",
       "  Operation(job_id=1, op_id=2, machine_type=1, duration=6)],\n",
       " [Operation(job_id=2, op_id=0, machine_type=1, duration=5),\n",
       "  Operation(job_id=2, op_id=1, machine_type=1, duration=6),\n",
       "  Operation(job_id=2, op_id=2, machine_type=1, duration=3)]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSPReaderJSON().read_instance('test.json').jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropies for datasets with pool_size = 36\n",
    "\n",
    "entropy0_2 = [0.5, 0.5]\n",
    "entropy0_3 = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
    "entropy0_4 = [0.08333333333333333, 0.16666666666666666, 0.25, 0.08333333333333333, 0.4166666666666667]\n",
    "entropy0_5 = [0.3333333333333333, 0.16666666666666666, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.16666666666666666]\n",
    "entropy0_6 = [0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.16666666666666666, 0.08333333333333333, 0.16666666666666666, 0.16666666666666666, 0.08333333333333333]\n",
    "entropy0_7 = [0.05555555555555555, 0.1111111111111111, 0.027777777777777776, 0.05555555555555555, 0.05555555555555555, 0.16666666666666666, 0.16666666666666666, 0.05555555555555555, 0.027777777777777776, 0.027777777777777776, 0.08333333333333333, 0.027777777777777776, 0.05555555555555555, 0.05555555555555555, 0.027777777777777776]\n",
    "entropy0_8 = [0.16666666666666666, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.05555555555555555, 0.027777777777777776, 0.05555555555555555, 0.027777777777777776, 0.027777777777777776, 0.05555555555555555, 0.05555555555555555, 0.027777777777777776, 0.027777777777777776, 0.05555555555555555, 0.027777777777777776, 0.08333333333333333, 0.05555555555555555, 0.08333333333333333, 0.027777777777777776]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_instances = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.5]\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "[0.08333333333333333, 0.16666666666666666, 0.25, 0.08333333333333333, 0.4166666666666667]\n",
      "[0.3333333333333333, 0.16666666666666666, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.16666666666666666]\n",
      "[0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.16666666666666666, 0.08333333333333333, 0.16666666666666666, 0.16666666666666666, 0.08333333333333333]\n",
      "[0.05555555555555555, 0.1111111111111111, 0.027777777777777776, 0.05555555555555555, 0.05555555555555555, 0.16666666666666666, 0.16666666666666666, 0.05555555555555555, 0.027777777777777776, 0.027777777777777776, 0.08333333333333333, 0.027777777777777776, 0.05555555555555555, 0.05555555555555555, 0.027777777777777776]\n",
      "[0.16666666666666666, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.05555555555555555, 0.027777777777777776, 0.05555555555555555, 0.027777777777777776, 0.027777777777777776, 0.05555555555555555, 0.05555555555555555, 0.027777777777777776, 0.027777777777777776, 0.05555555555555555, 0.027777777777777776, 0.08333333333333333, 0.05555555555555555, 0.08333333333333333, 0.027777777777777776]\n"
     ]
    }
   ],
   "source": [
    "for entropy_val in range(2, 9, 1):\n",
    "\n",
    "    dir_path = f\"data/entropy_datasets/entropy0_{entropy_val}/\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    for i in range(number_of_instances):\n",
    "        instance = RandomJSPGeneratorOperationDistirbution(num_jobs=6, num_operations=6, max_op_duration=9).generate(eval(f\"entropy0_{entropy_val}\"))\n",
    "        file_name = f\"entropy0_{entropy_val}_{i}\"\n",
    "        JSPWriterJSON().write_instance(instance, f\"{dir_path}/{file_name}\", file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c17c7798a234b4ec4e31009dea6d0ff377deb5cfd05df96186109883c898b2c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
